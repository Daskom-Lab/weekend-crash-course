{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import tensorflow as tf"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "mnist = tf.keras.datasets.mnist\r\n",
    "#load dataset, tulisan tangan digit dari 0 sampai 9 (mnist namanya)\r\n",
    "(x_train,y_train),(x_test,y_test)=mnist.load_data()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "x_train[12]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,  12,  99,  91, 142, 155, 246, 182, 155, 155, 155,\n",
       "        155, 131,  52,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0, 138, 254, 254, 254, 254, 254, 254, 254, 254, 254,\n",
       "        254, 254, 252, 210, 122,  33,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0, 220, 254, 254, 254, 235, 189, 189, 189, 189, 150,\n",
       "        189, 205, 254, 254, 254,  75,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,  35,  74,  35,  35,  25,   0,   0,   0,   0,   0,\n",
       "          0,  13, 224, 254, 254, 153,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  90, 254, 254, 247,  53,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,\n",
       "        152, 246, 254, 254,  49,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  66, 158,\n",
       "        254, 254, 249, 103,   8,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  54, 251, 254,\n",
       "        254, 254, 248,  74,   5,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 140, 254, 254,\n",
       "        254, 254, 254, 254, 202, 125,  45,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  58, 181, 234,\n",
       "        254, 254, 254, 254, 254, 254, 252, 140,  22,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  30,\n",
       "         50,  73, 155, 253, 254, 254, 254, 254, 191,   2,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,  91, 200, 254, 254, 254, 254, 118,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   4, 192, 254, 254, 254, 154,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0, 141, 254, 254, 254, 116,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  25, 126,  86,   0,   0,\n",
       "          0,   0,   0,   0,   3, 188, 254, 254, 250,  61,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  24, 209, 254,  15,   0,   0,\n",
       "          0,   0,   0,  23, 137, 254, 254, 254, 209,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 168, 254, 254,  48,   9,   0,\n",
       "          0,   9, 127, 241, 254, 254, 255, 242,  63,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 101, 254, 254, 254, 205, 190,\n",
       "        190, 205, 254, 254, 254, 254, 242,  67,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  33, 166, 254, 254, 254, 254,\n",
       "        254, 254, 254, 254, 250, 138,  55,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   7,  88, 154, 116, 194,\n",
       "        194, 154, 154,  88,  49,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "#wkwkkw yaudah kita gambar aja kali ya\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "contoh=plt.imshow(x_train[12],cmap='gray')\r\n",
    "#makin putih makin 255 makin hitam makin 0"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "#data kita reshape dulu, biar gampang komputer cerna nya\r\n",
    "\r\n",
    "x_train=x_train.reshape(60000,28,28,1)\r\n",
    "x_test=x_test.reshape(10000,28,28,1)\r\n",
    "x_train=x_train/255.0\r\n",
    "x_test=x_test/255.0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Parameters \r\n",
    "learning_rate = 0.001 \r\n",
    "training_epochs = 20 \r\n",
    "batch_size = 100 \r\n",
    "display_step = 1 \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Network Parameters \r\n",
    "n_hidden_1 = 256 "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# 1st layer num features\r\n",
    "n_hidden_2 = 256 # 2nd layer num features \r\n",
    "n_input = 784 # MNIST data input (img shape: 28*28) \r\n",
    "n_classes = 10 \r\n",
    "# MNIST total classes (0-9 digits) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# tf Graph input \r\n",
    "x = tf.TensorArray(\"float\", [None, n_input]) \r\n",
    "y = tf.TensorArray(\"float\", [None, n_classes]) "
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'list' object cannot be interpreted as an integer",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-d72a21dcf61f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# tf Graph input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorArray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"float\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_input\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorArray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"float\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\tensor_array_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dtype, size, dynamic_size, clear_after_read, tensor_array_name, handle, flow, infer_shape, element_shape, colocate_with_first_write_call, name)\u001b[0m\n\u001b[0;32m   1066\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1067\u001b[0m       \u001b[0mimplementation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_GraphTensorArray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1068\u001b[1;33m     self._implementation = implementation(\n\u001b[0m\u001b[0;32m   1069\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m         \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\tensor_array_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    716\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m       \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 718\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensor_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    719\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    720\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'list' object cannot be interpreted as an integer"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# weights layer 1 \r\n",
    "h = tf.Variable(tf.random_normal([n_input, n_hidden_1])) # bias layer 1 \r\n",
    "bias_layer_1 = tf.Variable(tf.random_normal([n_hidden_1])) \r\n",
    "# layer 1 \r\n",
    "layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, h), bias_layer_1)) \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# weights layer 2 \r\n",
    "w = tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# bias layer 2 \r\n",
    "bias_layer_2 = tf.Variable(tf.random_normal([n_hidden_2])) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# layer 2 \r\n",
    "layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, w), bias_layer_2)) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# weights output layer \r\n",
    "output = tf.Variable(tf.random_normal([n_hidden_2, n_classes])) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# biar output layer \r\n",
    "bias_output = tf.Variable(tf.random_normal([n_classes])) \r\n",
    "# output layer \r\n",
    "output_layer = tf.matmul(layer_2, output) + bias_output\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# cost function \r\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\r\n",
    "   logits = output_layer, labels = y)) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(output_layer, y)) \r\n",
    "# optimizer \r\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost) \r\n",
    "# optimizer = tf.train.GradientDescentOptimizer(\r\n",
    "#   learning_rate = learning_rate).minimize(cost) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot settings \r\n",
    "avg_set = [] \r\n",
    "epoch_set = [] "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Launch the graph \r\n",
    "with tf.Session() as sess: \r\n",
    "   sess.run(init) \r\n",
    "   \r\n",
    "   # Training cycle\r\n",
    "   for epoch in range(training_epochs): \r\n",
    "      avg_cost = 0. \r\n",
    "      total_batch = int(mnist.train.num_examples / batch_size) \r\n",
    "      \r\n",
    "      # Loop over all batches \r\n",
    "      for i in range(total_batch): \r\n",
    "         batch_xs, batch_ys = mnist.train.next_batch(batch_size) \r\n",
    "         # Fit training using batch data \r\n",
    "         sess.run(optimizer, feed_dict = {x: batch_xs, y: batch_ys}) \r\n",
    "         # Compute average loss \r\n",
    "         avg_cost += sess.run(cost, feed_dict = {x: batch_xs, y: batch_ys}) / total_batch\r\n",
    "      # Display logs per epoch step \r\n",
    "      if epoch % display_step == 0: \r\n",
    "         print(\"Epoch:\", '%04d' % (epoch + 1), \"cost=\", \"{:.9f}\".format(avg_cost))\r\n",
    "      avg_set.append(avg_cost) \r\n",
    "      epoch_set.append(epoch + 1)\r\n",
    "   print(\"Training phase finished\" )\r\n",
    "\r\n",
    "   plt.plot(epoch_set, avg_set, 'o', label = 'MLP Training phase') \r\n",
    "   plt.ylabel('cost') \r\n",
    "   plt.xlabel('epoch') \r\n",
    "   plt.legend() \r\n",
    "   plt.show() \r\n",
    "   correct_prediction = tf.equal(tf.argmax(output_layer, 1), tf.argmax(y, 1)) \r\n",
    "   accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\")) \r\n",
    "   print(\"Model Accuracy:\", accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit (system)"
  },
  "interpreter": {
   "hash": "afa84da41580b5478eb3d82816b7c3ca810ce5a1a203e6d94c0c5545600c53ae"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}